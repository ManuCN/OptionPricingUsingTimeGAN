{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense,Flatten,Reshape,Dropout,LeakyReLU,BatchNormalization,Conv2D,Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img_grid(imgs, cols, rows):\n",
    "    axes=[]\n",
    "    fig=plt.figure()\n",
    "    num = 0\n",
    "    for x in range(cols*rows):\n",
    "        axes.append(fig.add_subplot(rows, cols, x+1) )\n",
    "        plt.imshow(tf.reshape(imgs[num],[28,28]), cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        num += 1\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, batch_size, coding_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.coding_size = coding_size\n",
    "        print(\"Model: initialized\")       \n",
    "    \n",
    "    def model_info(self):\n",
    "        self.GAN.summary()\n",
    "        print(\"\\n###### G ######\")\n",
    "        self.GAN.layers[0].summary()\n",
    "        print(\"\\n###### D ######\")\n",
    "        self.GAN.layers[1].summary()\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.GAN = tf.keras.models.load_model(filepath=path, compile=False)\n",
    "        self.generator, self.discriminator = self.GAN.layers\n",
    "        self.discriminator.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")\n",
    "        self.discriminator.trainable = False\n",
    "        self.GAN.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")\n",
    "\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(self.data).shuffle(buffer_size=1500)\n",
    "        self.dataset = self.dataset.batch(self.batch_size,drop_remainder=True).prefetch(1)\n",
    "\n",
    "    def train_model(self, epochs, path): \n",
    "        a = 0\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"{epoch+1} Epoch von {epochs}\")\n",
    "            b = 0\n",
    "            if a%15 == 0:\n",
    "                tf.keras.models.save_model(self.GAN, path)\n",
    "            a += 1\n",
    "            \n",
    "            for batch in self.dataset:\n",
    "                b += 1\n",
    "                if b%50 == 0:\n",
    "                    print(f\"\\t{b} Batch von {len(self.data)//self.batch_size}\")\n",
    "\n",
    "                #Diskriminatortraining\n",
    "                Z = tf.random.normal(shape=[self.batch_size, self.coding_size])\n",
    "                fake_imgs = self.generator(Z)\n",
    "                self.discriminator.trainable = True\n",
    "                self.discriminator.train_on_batch(tf.concat([fake_imgs, tf.dtypes.cast(batch,tf.float32)],axis=0), \n",
    "                                                  tf.constant([[0.0]] * self.batch_size + [[1.0]] * self.batch_size))\n",
    "                \n",
    "                #Generatortraining\n",
    "                self.discriminator.trainable = False\n",
    "                self.GAN.train_on_batch(tf.random.normal(shape=[self.batch_size, self.coding_size]),\n",
    "                                        tf.constant([[1.0]] * self.batch_size))\n",
    "\n",
    "        tf.keras.models.save_model(self.GAN, path)\n",
    "    \n",
    "    def generate_images(self, size, show=True):\n",
    "        Z = tf.random.normal(shape=[size,self.coding_size])\n",
    "        images = self.generator(Z)\n",
    "        if show:\n",
    "          for image in images:\n",
    "              plt.imshow(image.numpy().reshape(28,28),cmap=\"gray\")\n",
    "              plt.show()\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model):\n",
    "    def prepare_data(self, number=\"ALL\"):\n",
    "        (X_train, y_train) , (X_test, y_test) = mnist.load_data()\n",
    "        if number == \"ALL\":\n",
    "          self.data = X_train\n",
    "        else:\n",
    "          self.data = X_train[y_train==number]   \n",
    "\n",
    "    def prepare_GAN(self):\n",
    "        #Diskriminator      ==> 28x28=784 zu 150 zu 100 zu 1 \n",
    "        discriminator = Sequential()\n",
    "        discriminator.add(Flatten(input_shape=[28,28]))\n",
    "        discriminator.add(Dense(150,activation=\"relu\"))\n",
    "        discriminator.add(Dense(100,activation=\"relu\"))\n",
    "        discriminator.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "        #Generator          ==> 100 zu 150 zu 784 zu 28x28\n",
    "        generator = Sequential() \n",
    "        generator.add(Dense(100,activation=\"relu\",input_shape=[self.coding_size]))\n",
    "        generator.add(Dense(150,activation=\"relu\"))\n",
    "        generator.add(Dense(784,activation=\"sigmoid\"))\n",
    "        generator.add(Reshape([28,28]))\n",
    "\n",
    "        self.GAN = Sequential([generator,discriminator])\n",
    "        discriminator.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")\n",
    "        discriminator.trainable = False\n",
    "        self.GAN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(self.data).shuffle(buffer_size=1500)\n",
    "        self.dataset = self.dataset.batch(self.batch_size,drop_remainder=True).prefetch(1)\n",
    "        self.generator, self.discriminator = self.GAN.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(Model):\n",
    "    def prepare_data(self, number=\"ALL\"):\n",
    "        (X_train, y_train) , (X_test, y_test) = mnist.load_data()\n",
    "        X_train = X_train/255 #==> Normalisiert Werte auf Bereich zwischen 0 und 1 \n",
    "        X_train = X_train.reshape(-1,28,28,1) * 2 - 1 #==> Werte zwischen -1 und 1, da tanh in letzter Generator Layer\n",
    "        if number == \"ALL\":\n",
    "          self.data = X_train\n",
    "        else:\n",
    "          self.data = X_train[y_train==number]   \n",
    "\n",
    "    def prepare_DCGAN(self):\n",
    "        #Diskriminator\n",
    "        discriminator = Sequential()\n",
    "        discriminator.add(Conv2D(64,kernel_size=5,strides=2,padding=\"same\",activation=LeakyReLU(0.2),input_shape=[28,28,1])) #==> 28x28x1 zu 14x14x64\n",
    "        discriminator.add(Dropout(0.4))\n",
    "        discriminator.add(Conv2D(128,kernel_size=5,strides=2,padding=\"same\",activation=LeakyReLU(0.2))) #==> 14x14x64 zu 7x7x128\n",
    "        discriminator.add(Dropout(0.4))\n",
    "        discriminator.add(Flatten()) #==> 7x7x128 zu 6272\n",
    "        discriminator.add(Dense(1,activation=\"sigmoid\")) #==> O oder 1\n",
    "        \n",
    "        #Generator\n",
    "        generator = Sequential()\n",
    "        generator.add(Dense(7*7*128,input_shape=[self.coding_size])) #==> 6272\n",
    "        generator.add(Reshape([7,7,128])) #==> 6272 zu 7x7x128\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(Conv2DTranspose(64,kernel_size=5,strides=2, padding=\"same\",activation=\"relu\")) #==> 7x7x128 zu 14x14x64\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(Conv2DTranspose(1,kernel_size=5,strides=2, padding=\"same\",activation=\"tanh\")) #==> 14x14x64 zu 28x28x1\n",
    "\n",
    "        self.GAN = Sequential([generator,discriminator])\n",
    "        discriminator.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")\n",
    "        discriminator.trainable = False\n",
    "        self.GAN.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")\n",
    "\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(self.data).shuffle(buffer_size=1500)\n",
    "        self.dataset = self.dataset.batch(self.batch_size,drop_remainder=True).prefetch(1)\n",
    "        self.generator, self.discriminator = self.GAN.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(batch_size=32,coding_size=125)\n",
    "gan.prepare_data(number=0)\n",
    "gan.prepare_GAN()\n",
    "gan.train_model(epochs=1,path=\"SavedModelsGAN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_img_grid(gan.generate_images(size=8,show=False), 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(batch_size=30,coding_size=125)\n",
    "dcgan.prepare_data(number=0)\n",
    "dcgan.prepare_DCGAN()\n",
    "dcgan.train_model(epochs=1,path=\"SavedModelsDCGAN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_img_grid(dcgan.generate_images(size=8,show=False), 4, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
